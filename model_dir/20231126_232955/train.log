2023-11-26 23:29:55,311 Hello! This is Joey-NMT.
2023-11-26 23:29:55,317 Total params: 78895872
2023-11-26 23:29:55,318 Trainable parameters: ['decoder.bert_model.embeddings.LayerNorm.bias', 'decoder.bert_model.embeddings.LayerNorm.weight', 'decoder.bert_model.embeddings.position_embeddings.weight', 'decoder.bert_model.embeddings.token_type_embeddings.weight', 'decoder.bert_model.embeddings.word_embeddings.weight', 'decoder.bert_model.encoder.layer.0.attention.output.LayerNorm.bias', 'decoder.bert_model.encoder.layer.0.attention.output.LayerNorm.weight', 'decoder.bert_model.encoder.layer.0.crossattention.output.LayerNorm.bias', 'decoder.bert_model.encoder.layer.0.crossattention.output.LayerNorm.weight', 'decoder.bert_model.encoder.layer.0.crossattention.output.dense.bias', 'decoder.bert_model.encoder.layer.0.crossattention.output.dense.weight', 'decoder.bert_model.encoder.layer.0.crossattention.self.key.bias', 'decoder.bert_model.encoder.layer.0.crossattention.self.key.weight', 'decoder.bert_model.encoder.layer.0.crossattention.self.query.bias', 'decoder.bert_model.encoder.layer.0.crossattention.self.query.weight', 'decoder.bert_model.encoder.layer.0.crossattention.self.value.bias', 'decoder.bert_model.encoder.layer.0.crossattention.self.value.weight', 'decoder.bert_model.encoder.layer.0.intermediate.dense.bias', 'decoder.bert_model.encoder.layer.0.intermediate.dense.weight', 'decoder.bert_model.encoder.layer.0.output.LayerNorm.bias', 'decoder.bert_model.encoder.layer.0.output.LayerNorm.weight', 'decoder.bert_model.encoder.layer.0.output.dense.bias', 'decoder.bert_model.encoder.layer.0.output.dense.weight', 'decoder.bert_model.encoder.layer.1.attention.output.LayerNorm.bias', 'decoder.bert_model.encoder.layer.1.attention.output.LayerNorm.weight', 'decoder.bert_model.encoder.layer.1.crossattention.output.LayerNorm.bias', 'decoder.bert_model.encoder.layer.1.crossattention.output.LayerNorm.weight', 'decoder.bert_model.encoder.layer.1.crossattention.output.dense.bias', 'decoder.bert_model.encoder.layer.1.crossattention.output.dense.weight', 'decoder.bert_model.encoder.layer.1.crossattention.self.key.bias', 'decoder.bert_model.encoder.layer.1.crossattention.self.key.weight', 'decoder.bert_model.encoder.layer.1.crossattention.self.query.bias', 'decoder.bert_model.encoder.layer.1.crossattention.self.query.weight', 'decoder.bert_model.encoder.layer.1.crossattention.self.value.bias', 'decoder.bert_model.encoder.layer.1.crossattention.self.value.weight', 'decoder.bert_model.encoder.layer.1.intermediate.dense.bias', 'decoder.bert_model.encoder.layer.1.intermediate.dense.weight', 'decoder.bert_model.encoder.layer.1.output.LayerNorm.bias', 'decoder.bert_model.encoder.layer.1.output.LayerNorm.weight', 'decoder.bert_model.encoder.layer.1.output.dense.bias', 'decoder.bert_model.encoder.layer.1.output.dense.weight', 'decoder.bert_model.pooler.dense.bias', 'decoder.bert_model.pooler.dense.weight', 'decoder.input_layer.weight', 'decoder.layer_norm.bias', 'decoder.layer_norm.weight', 'decoder.output_layer.weight', 'encoder.bert_model.embeddings.LayerNorm.bias', 'encoder.bert_model.embeddings.LayerNorm.weight', 'encoder.bert_model.embeddings.position_embeddings.weight', 'encoder.bert_model.embeddings.token_type_embeddings.weight', 'encoder.bert_model.embeddings.word_embeddings.weight', 'encoder.bert_model.encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.bert_model.encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.bert_model.encoder.layer.0.intermediate.dense.bias', 'encoder.bert_model.encoder.layer.0.intermediate.dense.weight', 'encoder.bert_model.encoder.layer.0.output.LayerNorm.bias', 'encoder.bert_model.encoder.layer.0.output.LayerNorm.weight', 'encoder.bert_model.encoder.layer.0.output.dense.bias', 'encoder.bert_model.encoder.layer.0.output.dense.weight', 'encoder.bert_model.encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.bert_model.encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.bert_model.encoder.layer.1.intermediate.dense.bias', 'encoder.bert_model.encoder.layer.1.intermediate.dense.weight', 'encoder.bert_model.encoder.layer.1.output.LayerNorm.bias', 'encoder.bert_model.encoder.layer.1.output.LayerNorm.weight', 'encoder.bert_model.encoder.layer.1.output.dense.bias', 'encoder.bert_model.encoder.layer.1.output.dense.weight', 'encoder.bert_model.pooler.dense.bias', 'encoder.bert_model.pooler.dense.weight', 'encoder.input_layer.weight', 'encoder.layer_norm.bias', 'encoder.layer_norm.weight', 'sgn_embed.ln.bias', 'sgn_embed.ln.weight', 'sgn_embed.norm.norm.bias', 'sgn_embed.norm.norm.weight', 'txt_embed.lut.weight', 'txt_embed.norm.norm.bias', 'txt_embed.norm.norm.weight']
2023-11-26 23:29:55,320 cfg.name                           : phoenix14t_bert2bert
2023-11-26 23:29:55,320 cfg.data.data_path                 : ./data
2023-11-26 23:29:55,320 cfg.data.version                   : phoenix_2014_trans
2023-11-26 23:29:55,321 cfg.data.sgn                       : sign
2023-11-26 23:29:55,321 cfg.data.txt                       : text
2023-11-26 23:29:55,321 cfg.data.gls                       : gloss
2023-11-26 23:29:55,321 cfg.data.train                     : phoenix14t.pami0.train
2023-11-26 23:29:55,321 cfg.data.dev                       : phoenix14t.pami0.dev
2023-11-26 23:29:55,321 cfg.data.test                      : phoenix14t.pami0.test
2023-11-26 23:29:55,321 cfg.data.feature_size              : 1024
2023-11-26 23:29:55,321 cfg.data.level                     : word
2023-11-26 23:29:55,321 cfg.data.txt_lowercase             : True
2023-11-26 23:29:55,321 cfg.data.max_sent_length           : 400
2023-11-26 23:29:55,321 cfg.data.random_train_subset       : -1
2023-11-26 23:29:55,321 cfg.data.random_dev_subset         : -1
2023-11-26 23:29:55,321 cfg.testing.recognition_beam_sizes : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
2023-11-26 23:29:55,321 cfg.testing.translation_beam_sizes : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
2023-11-26 23:29:55,321 cfg.testing.translation_beam_alphas : [-1, 0, 1, 2, 3, 4, 5]
2023-11-26 23:29:55,321 cfg.training.reset_best_ckpt       : False
2023-11-26 23:29:55,321 cfg.training.reset_scheduler       : False
2023-11-26 23:29:55,321 cfg.training.reset_optimizer       : False
2023-11-26 23:29:55,322 cfg.training.random_seed           : 2021
2023-11-26 23:29:55,322 cfg.training.model_dir             : ./model_dir/
2023-11-26 23:29:55,322 cfg.training.recognition_loss_weight : 0.0
2023-11-26 23:29:55,322 cfg.training.translation_loss_weight : 1.0
2023-11-26 23:29:55,322 cfg.training.eval_metric           : bleu
2023-11-26 23:29:55,322 cfg.training.optimizer             : adam
2023-11-26 23:29:55,322 cfg.training.learning_rate         : 0.0003
2023-11-26 23:29:55,322 cfg.training.batch_size            : 32
2023-11-26 23:29:55,322 cfg.training.num_valid_log         : 5
2023-11-26 23:29:55,322 cfg.training.epochs                : 5000000
2023-11-26 23:29:55,322 cfg.training.early_stopping_metric : eval_metric
2023-11-26 23:29:55,322 cfg.training.batch_type            : sentence
2023-11-26 23:29:55,322 cfg.training.translation_normalization : batch
2023-11-26 23:29:55,322 cfg.training.eval_recognition_beam_size : 1
2023-11-26 23:29:55,322 cfg.training.eval_translation_beam_size : 1
2023-11-26 23:29:55,322 cfg.training.eval_translation_beam_alpha : -1
2023-11-26 23:29:55,322 cfg.training.overwrite             : False
2023-11-26 23:29:55,322 cfg.training.shuffle               : True
2023-11-26 23:29:55,322 cfg.training.use_cuda              : False
2023-11-26 23:29:55,322 cfg.training.translation_max_output_length : 30
2023-11-26 23:29:55,322 cfg.training.keep_last_ckpts       : 1
2023-11-26 23:29:55,322 cfg.training.batch_multiplier      : 1
2023-11-26 23:29:55,322 cfg.training.logging_freq          : 100
2023-11-26 23:29:55,322 cfg.training.validation_freq       : 100
2023-11-26 23:29:55,322 cfg.training.betas                 : [0.9, 0.998]
2023-11-26 23:29:55,322 cfg.training.scheduling            : plateau
2023-11-26 23:29:55,322 cfg.training.learning_rate_min     : 1e-07
2023-11-26 23:29:55,323 cfg.training.weight_decay          : 0.001
2023-11-26 23:29:55,323 cfg.training.patience              : 8
2023-11-26 23:29:55,323 cfg.training.decrease_factor       : 0.7
2023-11-26 23:29:55,323 cfg.training.label_smoothing       : 0.0
2023-11-26 23:29:55,323 cfg.model.initializer              : xavier
2023-11-26 23:29:55,323 cfg.model.bias_initializer         : zeros
2023-11-26 23:29:55,323 cfg.model.init_gain                : 1.0
2023-11-26 23:29:55,323 cfg.model.embed_initializer        : xavier
2023-11-26 23:29:55,323 cfg.model.embed_init_gain          : 1.0
2023-11-26 23:29:55,323 cfg.model.tied_softmax             : False
2023-11-26 23:29:55,323 cfg.model.encoder.type             : BERT
2023-11-26 23:29:55,323 cfg.model.encoder.pretrain         : True
2023-11-26 23:29:55,323 cfg.model.encoder.pretrained_name  : bert-base-uncased
2023-11-26 23:29:55,323 cfg.model.encoder.num_layers       : 2
2023-11-26 23:29:55,323 cfg.model.encoder.num_heads        : 12
2023-11-26 23:29:55,323 cfg.model.encoder.freeze_pt        : finetune_ff
2023-11-26 23:29:55,323 cfg.model.encoder.freeze           : False
2023-11-26 23:29:55,323 cfg.model.encoder.embeddings.embedding_dim : 768
2023-11-26 23:29:55,323 cfg.model.encoder.embeddings.scale : False
2023-11-26 23:29:55,323 cfg.model.encoder.embeddings.dropout : 0.1
2023-11-26 23:29:55,323 cfg.model.encoder.embeddings.norm_type : batch
2023-11-26 23:29:55,323 cfg.model.encoder.embeddings.activation_type : softsign
2023-11-26 23:29:55,323 cfg.model.encoder.hidden_size      : 768
2023-11-26 23:29:55,323 cfg.model.encoder.dropout          : 0.1
2023-11-26 23:29:55,323 cfg.model.decoder.type             : BERT
2023-11-26 23:29:55,323 cfg.model.decoder.pretrain         : True
2023-11-26 23:29:55,323 cfg.model.decoder.pretrained_name  : bert-base-uncased
2023-11-26 23:29:55,323 cfg.model.decoder.num_layers       : 2
2023-11-26 23:29:55,324 cfg.model.decoder.num_heads        : 12
2023-11-26 23:29:55,324 cfg.model.decoder.freeze_pt        : finetune_ff
2023-11-26 23:29:55,324 cfg.model.decoder.freeze           : False
2023-11-26 23:29:55,324 cfg.model.decoder.embeddings.embedding_dim : 768
2023-11-26 23:29:55,324 cfg.model.decoder.embeddings.scale : False
2023-11-26 23:29:55,324 cfg.model.decoder.embeddings.dropout : 0.1
2023-11-26 23:29:55,324 cfg.model.decoder.embeddings.norm_type : batch
2023-11-26 23:29:55,324 cfg.model.decoder.embeddings.activation_type : softsign
2023-11-26 23:29:55,324 cfg.model.decoder.hidden_size      : 768
2023-11-26 23:29:55,324 cfg.model.decoder.ff_size          : 2048
2023-11-26 23:29:55,324 cfg.model.decoder.dropout          : 0.1
2023-11-26 23:29:55,324 Data set sizes: 
	train 7095,
	valid 519,
	test 642
2023-11-26 23:29:55,324 First training example:
	[GLS] JETZT WETTER MORGEN DONNERSTAG ZWOELF FEBRUAR
	[TXT] und nun die wettervorhersage für morgen donnerstag den zwölften august .
2023-11-26 23:29:55,324 First 10 words (gls): (0) <si> (1) <unk> (2) <pad> (3) REGEN (4) REGION (5) IX (6) KOMMEN (7) MORGEN (8) NORD (9) SONNE
2023-11-26 23:29:55,324 First 10 words (txt): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) . (5) und (6) im (7) es (8) der (9) am
2023-11-26 23:29:55,324 Number of unique glosses (types): 1087
2023-11-26 23:29:55,324 Number of unique words (types): 2889
2023-11-26 23:29:55,324 SignModel(
	encoder=BERTEncoder(num_layers=2, num_heads=12),
	decoder=BERTDecoder(num_layers=2, num_heads=12),
	sgn_embed=SpatialEmbeddings(embedding_dim=768, input_size=1024),
	txt_embed=Embeddings(embedding_dim=768, vocab_size=2889))
2023-11-26 23:29:55,328 EPOCH 1
